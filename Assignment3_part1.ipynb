{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffnTRbCUFufA",
        "outputId": "ed96a75e-6e9a-45dc-dc0e-c87010a7c067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 6s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               51300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1389188 (5.30 MB)\n",
            "Trainable params: 1388292 (5.30 MB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "782/782 [==============================] - 457s 579ms/step - loss: 4.2121 - accuracy: 0.0660 - val_loss: 3.6758 - val_accuracy: 0.1263\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 449s 574ms/step - loss: 3.6583 - accuracy: 0.1364 - val_loss: 3.3440 - val_accuracy: 0.1865\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 456s 583ms/step - loss: 3.3094 - accuracy: 0.1922 - val_loss: 2.8423 - val_accuracy: 0.2803\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 453s 579ms/step - loss: 3.0141 - accuracy: 0.2440 - val_loss: 2.6190 - val_accuracy: 0.3229\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 436s 557ms/step - loss: 2.7934 - accuracy: 0.2863 - val_loss: 2.6153 - val_accuracy: 0.3332\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 435s 556ms/step - loss: 2.6205 - accuracy: 0.3234 - val_loss: 2.2777 - val_accuracy: 0.3925\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 433s 553ms/step - loss: 2.4643 - accuracy: 0.3526 - val_loss: 2.2074 - val_accuracy: 0.4161\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 454s 581ms/step - loss: 2.3213 - accuracy: 0.3848 - val_loss: 2.0783 - val_accuracy: 0.4443\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 453s 579ms/step - loss: 2.1998 - accuracy: 0.4114 - val_loss: 1.9775 - val_accuracy: 0.4675\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 430s 550ms/step - loss: 2.0820 - accuracy: 0.4348 - val_loss: 1.8834 - val_accuracy: 0.4898\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 432s 552ms/step - loss: 1.9796 - accuracy: 0.4605 - val_loss: 1.8895 - val_accuracy: 0.4960\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 470s 601ms/step - loss: 1.8897 - accuracy: 0.4814 - val_loss: 1.8191 - val_accuracy: 0.5054\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 437s 559ms/step - loss: 1.7988 - accuracy: 0.5003 - val_loss: 1.7904 - val_accuracy: 0.5116\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 420s 538ms/step - loss: 1.7176 - accuracy: 0.5213 - val_loss: 1.7493 - val_accuracy: 0.5236\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 419s 536ms/step - loss: 1.6460 - accuracy: 0.5366 - val_loss: 1.7060 - val_accuracy: 0.5344\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 453s 580ms/step - loss: 1.5848 - accuracy: 0.5514 - val_loss: 1.6867 - val_accuracy: 0.5389\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 475s 608ms/step - loss: 1.5159 - accuracy: 0.5671 - val_loss: 1.6783 - val_accuracy: 0.5449\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 450s 576ms/step - loss: 1.4611 - accuracy: 0.5811 - val_loss: 1.6462 - val_accuracy: 0.5561\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 452s 578ms/step - loss: 1.4097 - accuracy: 0.5931 - val_loss: 1.6379 - val_accuracy: 0.5536\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 476s 608ms/step - loss: 1.3646 - accuracy: 0.6025 - val_loss: 1.6541 - val_accuracy: 0.5498\n",
            "Epoch 21/50\n",
            " 69/782 [=>............................] - ETA: 6:40 - loss: 1.2985 - accuracy: 0.6286"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Load the CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize the images to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices (one-hot encoding)\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=50,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    shuffle=True)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdptjutlMgty"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}