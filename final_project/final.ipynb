{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85442a1-6970-4015-8412-ba2ecd19dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Predicted Digit: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Predicted Digit: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted Digit: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted Digit: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Predicted Digit: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Predicted Digit: 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted Digit: 7\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "DRAW_COLOR = (255, 255, 255)  \n",
    "ERASE_COLOR = (0, 0, 0)  \n",
    "DRAW_THICKNESS = 10\n",
    "ERASER_THICKNESS = 40\n",
    "LANDMARK_COLOR = (0, 255, 255)  \n",
    "LINE_COLOR = (0, 255, 0)  \n",
    "LINE_THICKNESS = 3 \n",
    "\n",
    "ICONS = {\n",
    "    'blue': (100, 50, (255, 0, 0)),  \n",
    "    'green': (200, 50, (0, 255, 0)), \n",
    "    'eraser': (300, 50, (255, 255, 255)),  \n",
    "    'predict': (400, 50, (255, 255, 255))  \n",
    "}\n",
    "ICON_RADIUS = 30\n",
    "ICON_HIGHLIGHT_SCALE = 2  \n",
    "\n",
    "\n",
    "model = load_model('mnist_cnn_model2.h5')\n",
    "\n",
    "\n",
    "HAND_CONNECTIONS = [\n",
    "    (0, 1), (1, 2), (2, 3), (3, 4),  \n",
    "    (0, 5), (5, 6), (6, 7), (7, 8),  \n",
    "    (0, 9), (9, 10), (10, 11), (11, 12),  \n",
    "    (0, 13), (13, 14), (14, 15), (15, 16),  \n",
    "    (0, 17), (17, 18), (18, 19), (19, 20)  \n",
    "]\n",
    "\n",
    "def is_clicked(landmarks, index1, index2, threshold=30):\n",
    "    x1, y1 = int(landmarks[index1].x * width), int(landmarks[index1].y * height)\n",
    "    x2, y2 = int(landmarks[index2].x * width), int(landmarks[index2].y * height)\n",
    "    return np.sqrt((x1 - x2)**2 + (y1 - y2)**2) < threshold\n",
    "\n",
    "def draw_icons(frame, highlighted_icon=None):\n",
    "    for icon, (x, y, color) in ICONS.items():\n",
    "        radius = ICON_RADIUS * ICON_HIGHLIGHT_SCALE if highlighted_icon == icon else ICON_RADIUS\n",
    "        cv2.circle(frame, (x, y), radius, color, -1)\n",
    "        if icon == 'predict':\n",
    "            cv2.putText(frame, 'p', (x - 10, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 1 * ICON_HIGHLIGHT_SCALE, (0, 0, 0), 2)\n",
    "\n",
    "def preprocess_for_model(image):\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  \n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  \n",
    "    else:\n",
    "        gray_image = image  \n",
    "\n",
    "    resized_image = cv2.resize(gray_image, (28, 28), interpolation = cv2.INTER_AREA)\n",
    "    normailzed_image = tf.keras.utils.normalize(resized_image, axis = 1)\n",
    "    input_data = np.array(normailzed_image).reshape(-1,28,28,1)  \n",
    "    return input_data\n",
    "\n",
    "def draw_landmarks_and_connections(frame, landmarks):\n",
    "    for lm in landmarks:\n",
    "        x, y = int(lm.x * width), int(lm.y * height)\n",
    "        cv2.circle(frame, (x, y), 5, LANDMARK_COLOR, -1)  \n",
    "\n",
    "    for connection in HAND_CONNECTIONS:\n",
    "        start_idx, end_idx = connection\n",
    "        start_point = (int(landmarks[start_idx].x * width), int(landmarks[start_idx].y * height))\n",
    "        end_point = (int(landmarks[end_idx].x * width), int(landmarks[end_idx].y * height))\n",
    "        cv2.line(frame, start_point, end_point, LINE_COLOR, LINE_THICKNESS)  \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "canvas = np.zeros((480, 640, 3), dtype=\"uint8\")  \n",
    "color_canvas = np.zeros((480, 640, 3), dtype=\"uint8\")  \n",
    "prediction_canvas = np.zeros_like(canvas)  \n",
    "current_color = None  \n",
    "drawing = False\n",
    "last_point = None\n",
    "highlighted_icon = None\n",
    "predicted_digit = None  \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    height, width, _ = frame.shape\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        landmarks = result.multi_hand_landmarks[0].landmark\n",
    "\n",
    "        \n",
    "        draw_landmarks_and_connections(frame, landmarks)\n",
    "\n",
    "        thumb_tip = (int(landmarks[4].x * width), int(landmarks[4].y * height))\n",
    "        index_tip = (int(landmarks[8].x * width), int(landmarks[8].y * height))\n",
    "\n",
    "        \n",
    "        if is_clicked(landmarks, 4, 8, threshold=30):\n",
    "            new_highlighted_icon = None\n",
    "            for icon, (x, y, color) in ICONS.items():\n",
    "                if np.sqrt((index_tip[0] - x)**2 + (index_tip[1] - y)**2) < 30:\n",
    "                    new_highlighted_icon = icon\n",
    "                    if icon == 'blue':\n",
    "                        current_color = (255, 0, 0)\n",
    "                    elif icon == 'green':\n",
    "                        current_color = (0, 255, 0)\n",
    "                    elif icon == 'eraser':\n",
    "                        current_color = ERASE_COLOR\n",
    "                    elif icon == 'predict':\n",
    "                        \n",
    "                        gray_canvas = cv2.cvtColor(canvas, cv2.COLOR_BGR2GRAY)\n",
    "                        input_data = preprocess_for_model(gray_canvas)\n",
    "                        \n",
    "                        prediction = model.predict(input_data).argmax()\n",
    "                        predicted_digit = prediction\n",
    "                        print(f\"Predicted Digit: {predicted_digit}\")  \n",
    "\n",
    "            highlighted_icon = new_highlighted_icon\n",
    "\n",
    "            \n",
    "            if current_color:\n",
    "                if drawing:\n",
    "                    drawing = False\n",
    "                    last_point = None\n",
    "                else:\n",
    "                    drawing = True\n",
    "\n",
    "        if drawing and result.multi_hand_landmarks:\n",
    "            index_tip = (int(landmarks[8].x * width), int(landmarks[8].y * height))\n",
    "            if last_point:\n",
    "                if current_color == ERASE_COLOR:\n",
    "                    cv2.line(canvas, last_point, index_tip, ERASE_COLOR, ERASER_THICKNESS)\n",
    "                    cv2.line(color_canvas, last_point, index_tip, ERASE_COLOR, ERASER_THICKNESS)  \n",
    "                else:\n",
    "                    cv2.line(canvas, last_point, index_tip, DRAW_COLOR, DRAW_THICKNESS)  \n",
    "                    cv2.line(color_canvas, last_point, index_tip, current_color, DRAW_THICKNESS)  \n",
    "                    cv2.line(prediction_canvas, last_point, index_tip, DRAW_COLOR, DRAW_THICKNESS)  \n",
    "            last_point = index_tip\n",
    "\n",
    "    \n",
    "    draw_icons(frame, highlighted_icon)\n",
    "\n",
    "    \n",
    "    overlay = cv2.addWeighted(frame, 0.7, color_canvas, 0.3, 0)\n",
    "\n",
    "    \n",
    "    if predicted_digit is not None:\n",
    "        box_x1, box_y1 = width - 150, height - 100  \n",
    "        box_x2, box_y2 = width - 10, height - 20  \n",
    "        cv2.rectangle(overlay, (box_x1, box_y1), (box_x2, box_y2), (0, 0, 0), -1)\n",
    "        cv2.putText(overlay, f\"{predicted_digit}\", (box_x1 + 20, box_y2 - 20), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"Webcam Feed\", overlay)\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c509d0-8316-490c-b1f7-07762df27edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
